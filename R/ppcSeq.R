#' This is a generalisation of ifelse that acceots an object and return an objects
#'
#' @import dplyr
#' @import tidyr
#'
#' @param input.df A tibble
#' @param condition A boolean
#' @return A tibble
ifelse_pipe = function(.x, .p, .f1, .f2 = NULL) {
	switch(.p %>% `!` %>% sum(1),
				 as_mapper(.f1)(.x),
				 if (.f2 %>% is.null %>% `!`)
				 	as_mapper(.f2)(.x)
				 else
				 	.x)

}

#' format_for_MPI
#'
#' @description Format reference data frame for MPI
format_for_MPI = function(df, shards, sample_column){

	sample_column = enquo(sample_column)

	df %>%

		left_join(
			(.) %>%
				distinct(G) %>%
				arrange(G) %>%
				mutate( idx_MPI = head( rep(1:shards, (.) %>% nrow %>% `/` (shards) %>% ceiling ), n=(.) %>% nrow) ),
			by = "G"
		) %>%
		arrange(idx_MPI, G) %>%

		# Decide start - end location
		group_by(idx_MPI) %>%
		do(
			(.) %>%
				left_join(
					(.) %>%
						distinct(!!sample_column, G) %>%
						arrange(G) %>%
						count(G) %>%
						mutate(end = cumsum(n)) %>%
						mutate(start = c(1, .$end %>% rev() %>% `[` (-1) %>% rev %>% `+` (1))),
					by = "G"
				)
		) %>%
		ungroup() %>%

		# Add symbol MPI rows indexes - otherwise spread below gives error
		left_join(
			(.) %>%
				group_by(idx_MPI) %>%
				distinct(G) %>%
				arrange(G) %>%
				mutate(`symbol MPI row` = 1:n()) %>%
				ungroup,
			by = c("G", "idx_MPI")
		) %>%

		# Add counts MPI rows indexes
		group_by(idx_MPI) %>%
		arrange(G) %>%
		mutate(`read count MPI row` = 1:n()) %>%
		ungroup

}

#' add_partition
#'
#' @description Add partition column dto data frame
add_partition = function(df.input, partition_by, n_partitions){
	df.input %>%
		left_join(
			(.) %>%
				select(!!partition_by) %>%
				distinct %>%
				mutate(
					partition = 1:n() %>%
						divide_by(length((.))) %>%
						#	multiply_by(min(n_partitions, df.input %>% distinct(symbol) %>% nrow)) %>%
						multiply_by(n_partitions) %>%
						ceiling
				)
		)
}

#' Formula parser
#'
#' @param fm A formula
#' @return A character vector
#'
#'
parse_formula <- function(fm) {
	if(attr(terms(fm), "response") == 1) stop("The formula must be of the kind \"~ covariates\" ")
	else as.character(attr(terms(fm), "variables"))[-1]
}

#' Get matrix from tibble
#'
#' @import dplyr
#' @importFrom tidyr gather
#' @importFrom magrittr set_rownames
#'
#' @param tbl A tibble
#' @param rownames A character string of the rownames
#' @return A matrix
as_matrix <- function(tbl, rownames = NULL) {
	tbl %>%

		ifelse_pipe(
			tbl %>%
				ifelse_pipe(	!is.null(rownames),		~ .x %>% dplyr::select(-contains(rownames))	) %>%
				summarise_all(class) %>%
				gather(variable, class) %>%
				pull(class) %>%
				unique() %>%
				`%in%`(c("numeric", "integer")) %>% `!`() %>% any(),
			~ { warning("to_matrix says: there are NON-numerical columns, the matrix will NOT be numerical"); .x}
		) %>%
		as.data.frame() %>%

		# Deal with rownames column if present
		ifelse_pipe(
			!is.null(rownames),
			~ .x  %>%
				set_rownames(tbl %>% pull(!!rownames)) %>%
				select(-!!rownames)
		) %>%

		# Convert to matrix
		as.matrix()
}

#' vb_iterative
#'
#' @description Runs iteratively variational bayes until it suceeds
#'
#' @importFrom rstan vb
#'
#' @param model A Stan model
#' @param output_samples An integer of how many samples from posteriors
#' @param iter An integer of how many max iterations
#' @param tol_rel_obj A real
#'
#' @return A Stan fit object
#'
vb_iterative = function(model, output_samples, iter, tol_rel_obj, ...){
	res = NULL
	i = 0
	while(res %>% is.null | i > 5) {

		res = tryCatch(
			{
				my_res = vb(
					model,
					output_samples=output_samples,
					iter = iter,
					tol_rel_obj=tol_rel_obj,
					...
					#, pars=c("counts_rng", "exposure_rate", additional_parameters_to_save)
				)
				boolFalse<-T
				return(my_res)
			},
			error=function(e){ i = i + 1; writeLines(sprintf("Further attempt with Variational Bayes: %s", e)); return(NULL) },
			finally={}
		)
	}

	return(res)
}

#' Choose the number of chains baed on how many draws we need from the posterior distribution
#' Because there is a fix cost (warmup) to starting a new chain,
#' we need to use the minimum amount that we can parallelise
#' @param how_many_posterior_draws A real number of posterior draws needed
#' @param max_number_to_check A sane upper plateau
#'
#' @return A Stan fit object
find_optimal_number_of_chains = function(how_many_posterior_draws,
																				 max_number_to_check = 100) {
	foreach(cc = 2:max_number_to_check, .combine = bind_rows) %do%
		{
			tibble(chains = cc, tot = how_many_posterior_draws / cc + 150 * cc)
		} %>%
		filter(tot == tot %>% min) %>%
		pull(chains)

}

#' do_inference
#'
#' @description This function calls the stan model.
#'
#' @importFrom tibble tibble
#' @import rstan
#' @import dplyr
#' @importFrom tidyr spread
#' @import tidybayes
#' @importFrom foreach foreach
#' @importFrom foreach %do%
#' @importFrom magrittr %$%
#' @importFrom magrittr divide_by
#' @importFrom magrittr multiply_by
#' @importFrom purrr map2
#' @importFrom purrr map_int
#' @importFrom tidyTranscriptomics add_normalised_counts_bulk
#'
#' @param input.df A tibble including a gene name column | sample name column | read counts column | covariates column
#' @param formula A formula
#' @param sample_column A column name
#' @param gene_column A column name
#' @param value_column A column name
#' @param significance_column A column name
#' @param full_bayes A boolean
#' @param how_many_negative_controls An integer
#' @param how_many_posterior_draws An integer
#'
#' @return A tibble with additional columns
#'
do_inference = function(
	my_df,
	formula,
	sample_column ,
	gene_column ,
	value_column,
	significance_column ,
	do_check_column,
	full_bayes = F,
	C,
	X,
	lambda_mu_mu,
	cores,
	exposure_rate_multiplier, intercept_shift_scale,
	additional_parameters_to_save,
	adj_prob_theshold,
	to_exclude = tibble(S = integer(), G = integer()),
	truncation_compensation = 1,
	save_generated_quantities = F,
	inits_fx = "random",
	prior_from_discovery = tibble(`.variable` = character(), mean = numeric(), sd = numeric())
){

	sample_column = enquo(sample_column)
	gene_column = enquo(gene_column)
	value_column = enquo(value_column)
	significance_column = enquo(significance_column)
	do_check_column = enquo(do_check_column)


	how_many_to_check =
		my_df %>%
		filter(!!do_check_column) %>%
		distinct(!!gene_column) %>%
		nrow

	# Calculate the needed posterior draws
	how_many_posterior_draws =  5 %>% divide_by(adj_prob_theshold) %>% max(500)

	# Identify the optimal number of chain
	# based on how many draws we need from the posterior
	chains = find_optimal_number_of_chains(how_many_posterior_draws)

	# Find how many cores per chain, minimum 1 of course
	my_cores = cores %>% divide_by(chains) %>% floor %>% max(1)

	shards = my_cores

	counts_MPI =
		my_df %>%
		select(!!gene_column, !!sample_column, !!value_column, S, G) %>%
		format_for_MPI(shards, !!sample_column)

	G = counts_MPI %>% distinct(G) %>% nrow()
	S = counts_MPI %>% distinct(!!sample_column) %>% nrow()
	N = counts_MPI %>% distinct(idx_MPI, !!value_column, `read count MPI row`) %>%  count(idx_MPI) %>% summarise(max(n)) %>% pull(1)
	M = counts_MPI %>% distinct(start, idx_MPI) %>% count(idx_MPI) %>% pull(n) %>% max
	G_per_shard = counts_MPI %>% distinct(!!gene_column, idx_MPI) %>% count(idx_MPI) %>% pull(n) %>% as.array
	n_shards = min(shards, counts_MPI %>% distinct(idx_MPI) %>% nrow)
	G_per_shard_idx = c(0, counts_MPI %>% distinct(!!gene_column, idx_MPI) %>% count(idx_MPI) %>% pull(n) %>% cumsum)

	counts =
		counts_MPI %>%
		distinct(idx_MPI, !!value_column, `read count MPI row`)  %>%
		spread(idx_MPI,  !!value_column) %>%
		select(-`read count MPI row`) %>%
		replace(is.na(.), 0 %>% as.integer) %>%
		as_matrix() %>% t

	sample_idx =
		counts_MPI %>%
		distinct(idx_MPI, S, `read count MPI row`)  %>%
		spread(idx_MPI, S) %>%
		select(-`read count MPI row`) %>%
		replace(is.na(.), 0 %>% as.integer) %>%
		as_matrix() %>% t

	symbol_end =
		counts_MPI %>%
		distinct(idx_MPI, end, `symbol MPI row`)  %>%
		spread(idx_MPI, end) %>%
		bind_rows( (.) %>% head(n=1) %>%  mutate_all(function(x) {0}) ) %>%
		arrange(`symbol MPI row`) %>%
		select(-`symbol MPI row`) %>%
		replace(is.na(.), 0 %>% as.integer) %>%
		as_matrix() %>% t

	G_ind =
		counts_MPI %>%
		distinct(idx_MPI, G, `symbol MPI row`)  %>%
		spread(idx_MPI, G) %>%
		arrange(`symbol MPI row`) %>%
		select(-`symbol MPI row`) %>%
		replace(is.na(.), 0 %>% as.integer) %>%
		as_matrix() %>% t

	# Additional info for second pass ###############
	to_exclude_MPI =

		# If there are genes to exclude
		switch(
			to_exclude %>% nrow %>% `>` (0) %>% `!` %>% sum(1),
			foreach(s = 1:shards, .combine=full_join) %do% {
				counts_MPI %>%
					inner_join(to_exclude, by=c("S", "G")) %>%
					filter(idx_MPI == s) %>%
					distinct(idx_MPI, `read count MPI row`) %>%
					rowid_to_column %>%
					spread(idx_MPI, `read count MPI row`) %>%

					# If a shard is empty create a dummy data set to avoid error
					ifelse_pipe(	(.) %>% nrow == 0, ~ tibble(rowid = 1, !!as.symbol(s) := NA) )

			} %>%

			# Anonymous function - Add length array to the first row for indexing in MPI
			# Input: tibble
			# Output: tibble
			{
				bind_rows(
					(.) %>% map(function(x) x %>% is.na %>% `!` %>% as.numeric %>% sum) %>% unlist,
					(.)
				)
			} %>%

			select(-rowid) %>%
			replace(is.na(.), 0 %>% as.integer) %>%
			as_matrix() %>% t,

			# Otherwise
			matrix(rep(0,shards))
		)

	# Package data #################################

	counts_package =

		# Dimensions data sets
		rep(c(M, N, S), shards) %>%
		matrix(nrow = shards, byrow = T) %>%
		cbind(G_per_shard) %>%
		cbind(symbol_end) %>%
		cbind(sample_idx) %>%
		cbind(counts) %>%
		cbind(to_exclude_MPI)

	CP = ncol(counts_package)

	# Run model ####################################

	Sys.setenv("STAN_NUM_THREADS" = my_cores)

	# For debug purpose
	# fileConn<-file("~/.R/Makevars")
	# writeLines(c( "CXX14FLAGS += -O3","CXX14FLAGS += -DSTAN_THREADS", "CXX14FLAGS += -pthread"), fileConn)
	# close(fileConn)
	# pcc_seq_model = rstan::stan_model("inst/stan/negBinomial_MPI.stan")
	# fit = vb(
	# 	pcc_seq_model, #
	# 	output_samples=1000,
	# 	iter = 50000,
	# 	tol_rel_obj=0.001
	# )

	Sys.time() %>% print
	fit =
		switch(
			full_bayes %>% `!` %>% as.integer %>% sum(1),

			# MCMC
			sampling(
				stanmodels$negBinomial_MPI, #pcc_seq_model, #
				chains=chains, cores=chains,
				iter=(how_many_posterior_draws/chains) %>% ceiling %>% sum(150),
				warmup=150,
				save_warmup = FALSE,
				init = inits_fx,
				pars=c("counts_rng", "exposure_rate", additional_parameters_to_save)
			),

			# VB Repeat strategy for failures of vb
			vb_iterative(
				 stanmodels$negBinomial_MPI, #pcc_seq_model, #
				 output_samples=how_many_posterior_draws,
				 iter = 50000,
				 tol_rel_obj=0.005,
				 pars=c("counts_rng", "exposure_rate", additional_parameters_to_save)
			)
		)
	Sys.time() %>% print

	# Parse and return ###############################

	fit %>%
		rstan::summary("counts_rng", prob=c(adj_prob_theshold, 1-adj_prob_theshold)) %$%
		summary %>%
		as_tibble(rownames = ".variable") %>%
		separate(.variable, c(".variable", "S", "G"), sep="[\\[,\\]]", extra="drop") %>%
		mutate(S = S %>% as.integer, G = G %>% as.integer) %>%
		select(-one_of(c("n_eff","Rhat", "khat"))) %>%
		rename(`.lower` = (.) %>% ncol - 1, `.upper` = (.) %>% ncol) %>%

		# If generated quantities are saved
		ifelse_pipe(
			save_generated_quantities,
			~ .x %>%

				# Add generated quantities
				left_join(fit %>% tidybayes::gather_draws(counts_rng[S,G])) %>%

				# Nest them in the data frame
				group_by(`.variable`, S ,G, mean,se_mean , sd, `.lower`, `.upper`) %>%
				nest(.key = "generated quantities")
		) %>%

		# Add exposure rate
		left_join(
			fit %>%
				summary("exposure_rate") %$%
				summary %>%
				as_tibble(rownames = ".variable") %>%
				separate(.variable, c(".variable", "S"), sep="[\\[,\\]]", extra="drop") %>%
				mutate(S = S %>% as.integer) %>%
				rename(`exposure rate` = mean) %>%
				select(S, `exposure rate`),
			by="S"
		) %>%

		# Check if data is within posterior
		left_join(my_df, by = c("S", "G")) %>%
		filter((!!do_check_column)) %>% # Filter only DE genes
		rowwise() %>%
		mutate(`ppc` = !!value_column %>% between(`.lower`, `.upper`)) %>%
		mutate(`is higher than mean` = (!`ppc`) & (!!value_column > mean)) %>%
		ungroup %>%

		# Add annotation if sample belongs to high or low group
		left_join(
			X %>%
				as_tibble %>%
				select(2) %>%
				setNames("factor or interest") %>%
				mutate(S=1:n()) %>%
				mutate(`is group high` = `factor or interest` > mean(`factor or interest`)),
			by = "S"
		) %>%

		# Check if outlier might be deleterious for the statistics
		mutate(`deleterious outliers` = (!ppc) & (`is higher than mean` == `is group high`)) %>%

		# Add position in MPI package for next inference
		left_join(	counts_MPI %>% distinct(S, G, idx_MPI, `read count MPI row`), by = c("S", "G")	) %>%

		# Add initialisation values
		# bind_rows(
		# 	fit %>%
		# 		summary(c("lambda_mu_raw", "lambda_sigma", "sigma_slope", "sigma_intercept", "sigma_sigma")) %$%
		# 		summary %>%
		# 		as_tibble(rownames = ".variable") %>%
		# 		select(`.variable`, mean, sd)
		# ) %>%
		bind_rows(
			fit %>%
				summary("exposure_rate") %$%
				summary %>%
				as_tibble(rownames = ".variable") %>%
				separate(.variable, c(".variable", "S"), sep="[\\[,\\]]", extra="drop") %>%
				mutate( S = S %>% as.integer) %>%
				select(S, `.variable`, mean, sd)
		)
	# %>%
	# 	bind_rows(
	# 		fit %>%
	# 			summary(c("intercept", "alpha_sub_1", "alpha_2", "sigma_raw")) %$%
	# 			summary %>%
	# 			as_tibble(rownames = ".variable") %>%
	# 			separate(.variable, c(".variable", "G"), sep="[\\[,\\]]", extra="drop") %>%
	# 			mutate(G = G %>% as.integer) %>%
	# 			select(G, `.variable`, mean, sd)
	# 	)
}

inits_fx =
	function () {

		pars =
			res_discovery %>%
			filter(`.variable` != "counts_rng") %>%
			distinct(`.variable`) %>%
			pull(1)

		foreach(par = pars,	.final = function(x) setNames(x, pars)) %do% {

			res_discovery %>%
				filter(`.variable` == par) %>%
				mutate(init = rnorm(n(),mean, sd)) %>%
				mutate(init = 0) %>%
				select(`.variable`, S, G, init) %>%
				pull(init)
		}
	}

produce_plots = function(.x, value_column, sample_column, covariate){

	# Set plot theme
	my_theme =
		theme_bw() +
		theme(
			panel.border = element_blank(),
			axis.line = element_line(),
			panel.grid.major = element_line(size = 0.2),
			panel.grid.minor = element_line(size = 0.1),
			text = element_text(size=12),
			aspect.ratio=1,
			axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.5),
			strip.background = element_blank(),
			axis.title.x  = element_text(margin = margin(t = 10, r = 10, b = 10, l = 10)),
			axis.title.y  = element_text(margin = margin(t = 10, r = 10, b = 10, l = 10))
		)

	{
		ggplot(data = .x, aes(y=!!as.symbol(value_column), x=!!as.symbol(sample_column))) +
			geom_errorbar(aes(
				ymin=`.lower`,
				ymax=`.upper`
			), width=0, linetype="dashed", color="#D3D3D3") +
			geom_errorbar(aes(
				ymin=`.lower_2`,
				ymax=`.upper_2`,
				color =`deleterious outliers`
			), width=0) +
			scale_colour_manual(values = c( "TRUE"= "red", "FALSE"= "black")) +
			my_theme
	} %>%

		ifelse_pipe(
			covariate %>% is.null %>% `!`,
			~ .x + geom_point(aes(size=`exposure rate`, fill = !!as.symbol(covariate)), shape = 21),
			~ .x + geom_point(aes(size=`exposure rate`), shape=21, fill="black")
		)
}

other_non_used_code = function(){

	# Relation expected value, variance
	# fit_draws = fit@sim$samples[[1]] %>% bind_rows() %>% mutate(.draw = 1:n()) %>% gather(.variable, .value, -.draw)
	#
	# # Plot relation lambda sigma
	# fit_draws %>% filter(grepl("^alpha", .variable)) %>% separate(.variable, c(".variable", "C", "G"), sep="\\.") %>%
	# 	mutate(C = C %>% as.integer, G = G %>% as.integer) %>%
	# 	filter(C == 1) %>%
	# 	select(-C) %>%
	# 	bind_rows(
	# 		fit_draws %>% filter(grepl("^sigma_raw_param", .variable)) %>% separate(.variable, c(".variable", "G"), sep="\\.") %>%
	# 			mutate( G = G %>% as.integer)
	# 	) %>%
	# 	spread(.variable, .value) %>%
	# 	ggplot(aes(x=alpha, y=sigma_raw_param, group=G)) +
	# 	stat_ellipse( alpha=0.2) +
	# 	my_theme

	# fit %>%
	# 	tidybayes::spread_draws(counts_rng[S,G]) %>%
	# 	filter(G==1) %>%
	# 	ggplot(aes(x=counts_rng+1, group=S)) +
	# 	geom_density(fill="grey") +
	# 	geom_vline(data = my_df %>% filter(G==1), aes(xintercept = !!value_column, color=ct),
	# 		linetype="dotted",
	# 		size=1.5
	# 	) +
	# 	facet_wrap(~ S) +
	# 	my_theme
}


#' pcc_seq main
#'
#' @description This function calls the stan model.
#'
#' @importFrom tibble as_tibble
#' @import dplyr
#' @importFrom tidyr spread
#' @import tidybayes
#' @importFrom magrittr %$%
#' @importFrom magrittr divide_by
#' @importFrom magrittr multiply_by
#' @importFrom purrr map2
#' @importFrom purrr map_int
#' @importFrom tidyTranscriptomics add_normalised_counts_bulk
#'
#' @param input.df A tibble including a gene name column | sample name column | read counts column | covariates column
#' @param formula A formula
#' @param sample_column A column name
#' @param gene_column A column name
#' @param value_column A column name
#' @param significance_column A column name
#' @param full_bayes A boolean
#' @param how_many_negative_controls An integer
#' @param how_many_posterior_draws An integer

#'
#' @return A tibble with additional columns
#'
#' @export
#'
ppc_seq = function(
	input.df,
	formula = ~ 1,
	sample_column = `sample`,
	gene_column = `symbol`,
	value_column = `read count`,
	significance_column = `p-value`,
	do_check_column,
	full_bayes = F,
	how_many_negative_controls = 500,
	save_generated_quantities = F,       # For development purpose
	additional_parameters_to_save = c(), # For development purpose,
	cores = system("nproc", intern = TRUE) %>% as.integer %>% sum(-1),
	percent_false_positive_genes = "1%"
){

	sample_column = enquo(sample_column)
	gene_column = enquo(gene_column)
	value_column = enquo(value_column)
	significance_column = enquo(significance_column)
	do_check_column = enquo(do_check_column)

	# Check is testing environment is supported
	if((!full_bayes) & save_generated_quantities) stop("Variational Bayes does not support tidybayes needed for save_generated_quantities, use sampling")

	# Check percent FP input
	pfpg = percent_false_positive_genes %>% gsub("%$", "", .) %>% as.numeric
	if(pfpg %>% is.na | !(pfpg %>% between(0, 100))) stop("percent_false_positive_genes must be a string from > 0% to < 100%")

	# Plot theme
	my_theme =
		theme_bw() +
		theme(
			panel.border = element_blank(),
			axis.line = element_line(),
			panel.grid.major = element_line(size = 0.2),
			panel.grid.minor = element_line(size = 0.1),
			text = element_text(size=12),
			legend.position="bottom",
			#aspect.ratio=1,
			axis.text.x = element_text(angle = 90, hjust = 0.5, vjust=1),
			strip.background = element_blank(),
			axis.title.x  = element_text(margin = margin(t = 10, r = 10, b = 10, l = 10)),
			axis.title.y  = element_text(margin = margin(t = 10, r = 10, b = 10, l = 10))
		)

	########################################
	# For  reference MPI inference

	# Check if all trannscripts are non NA
	if(input.df %>% filter(!!gene_column %>% is.na) %>% nrow > 0) stop("There are NAs in the gene_column. Please filter those records")

	# Check if the counts column is an integer
	if(input.df %>% select(!!value_column) %>% sapply(class) != "integer")
		stop(
			sprintf(
				"The column %s must be of class integer. You can do as mutate(`%s` = `%s` %%>%% as.integer)",
				quo_name(value_column),
				quo_name(value_column),
				quo_name(value_column)
			)
		)

	# distinct_at is not released yet for dplyr, thus we have to use this trick
	my_df <- input.df %>%

		# Anonymous function - Select only significant genes plus background for efficient normalisation
		# Input: tibble
		# Ouyput: tibble
		{
			bind_rows(

				# Genes to check
				(.) %>%
					filter((!!do_check_column)),

				# Least changing genes, negative controls
				(.) %>%
					filter((!!do_check_column) %>% `!`) %>%
					inner_join(
						(.) %>%
							arrange(!!significance_column) %>%
							select(!!gene_column) %>%
							distinct() %>%
							tail(how_many_negative_controls),
						by = quo_name(gene_column)
						)
			)
		} %>%

		# Prepare the data frame
		select(!!gene_column, !!sample_column, !!value_column, one_of(parse_formula(formula)), !!do_check_column) %>%
		distinct() %>%

		# Add symbol idx
		left_join(
			(.) %>%
				distinct(!!gene_column) %>%
				mutate(G = 1:n()),
			by = quo_name(gene_column)
		) %>%

		# Add sample indeces
		mutate(S = factor(!!sample_column, levels = (.) %>% pull(!!sample_column) %>% unique) %>% as.integer)

	# Create design matrix
	X =
		model.matrix(
			object = formula,
			data =
				my_df %>%
				select(!!sample_column, one_of(parse_formula(formula))) %>%
				distinct %>% arrange(!!sample_column)
		)
	C = X %>% ncol

	########################################
	# Prior info

	lambda_mu_mu = 5.612671

	########################################
	# Build better scales

	exposure_rate_multiplier =
		my_df %>%
		add_normalised_counts_bulk(!!sample_column, !!gene_column, !!value_column) %>%
		distinct(!!sample_column, TMM, multiplier) %>%
		mutate(l = multiplier %>% log) %>%
		summarise(l %>% sd) %>%
		pull(`l %>% sd`)

	intercept_shift_scale =
		my_df %>%
		add_normalised_counts_bulk(!!sample_column, !!gene_column, !!value_column) %>%
		mutate(
			cc =
				!!as.symbol(sprintf("%s normalised",  quo_name(value_column))) %>%
				`+` (1) %>% log
					 ) %>%
		summarise(shift = cc %>% mean, scale = cc %>% sd) %>%
		as.numeric

	########################################
	# MODEL

	# Run the first discovery phase with permissive false discovery rate
	res_discovery =
		my_df %>%
		do_inference(
			formula,
			!!sample_column ,
			!!gene_column ,
			!!value_column ,
			!!significance_column ,
			!!do_check_column,
			full_bayes,
			C,
			X,
			lambda_mu_mu,
			cores,
			exposure_rate_multiplier,
			intercept_shift_scale,
			additional_parameters_to_save,
			adj_prob_theshold  = 0.05
		)

	# Columns of counts to be ignored from the inference
	to_exclude =
		res_discovery %>%
		filter(`.variable` == "counts_rng") %>%
		filter(`deleterious outliers`) %>%
		distinct(S, G, .lower, .upper)

	# Claculate how many popential non NB transcript I should check
	how_namy_to_exclude = to_exclude %>% nrow

	# Get the credible intervals for which account in the truncated NB model
	truncation_values =
		res_discovery %>%
		filter(`.variable` == "counts_rng") %>%
		distinct(S, G, .lower, .upper) %>%
		mutate(
			`.lower` = `.lower` %>% as.integer,
			`.upper` = `.upper` %>% as.integer
		)

	# Get the inferred values from first model to possibly use them in the second model as priors
	prior_from_discovery =
		res_discovery %>%
			filter(`.variable` != "counts_rng") %>%
			select(`.variable`, S, G, mean, sd)

	# Run the second test phase with the user selected false discovery rate
	res_test =
		my_df %>%
		do_inference(
			formula,
			!!sample_column ,
			!!gene_column ,
			!!value_column ,
			!!significance_column ,
			!!do_check_column,
			full_bayes,
			C,
			X,
			lambda_mu_mu,
			cores,
			exposure_rate_multiplier,
			intercept_shift_scale,
			additional_parameters_to_save,
			adj_prob_theshold = pfpg / 100 / (my_df %>% distinct(!!sample_column) %>% nrow) * 2, # * 2 because we just test one side of the distribution
			to_exclude = to_exclude,
			save_generated_quantities = save_generated_quantities,
			truncation_compensation = 0.7352941 # Taken by approximation study
		)

	# Merge results
	res_discovery %>%
		filter(`.variable` == "counts_rng") %>%
		select(
			S, G, !!gene_column, !!value_column, !!sample_column,
			`.lower`, `.upper`, `exposure rate`, !!as.symbol(parse_formula(formula)[1])
		) %>%

		# Attach results of tests
		left_join(
			res_test %>% 		filter(`.variable` == "counts_rng") %>%
				select(S, G, `.lower`, `.upper`, `deleterious outliers`, one_of("generated quantities")) %>%
				rename(`.lower_2` = `.lower`, `.upper_2` = `.upper`),
			by = c("S", "G")
		) %>%

		# Check if new package is installed with different sintax
		ifelse_pipe(
			packageVersion("tidyr") == "0.8.3.9000",
			~ .x %>% nest(`sample wise data` = c(-!!gene_column)),
			~ .x %>%
				group_by(!!gene_column) %>%
				nest(-!!gene_column, .key = `sample wise data` )
		) %>%

		# Create plots for every tested transcript
		mutate(
			plot =
				pmap(
					list(
						`sample wise data`,       # nested data for plot
						quo_name(value_column),   # name of value column
						quo_name(sample_column),  # name of sample column
						parse_formula(formula)[1] # main covariate
					),
					~ produce_plots(..1, ..2, ..3, ..4)
				)
		) %>%

		# Add summary statistics
		mutate(
			# `ppc samples failed` = map_int(data, ~ .x %>% pull(ppc) %>% `!` %>% sum),
			`tot deleterious outliers` = map_int(`sample wise data`, ~ .x %>% pull(`deleterious outliers`) %>% sum)
		)

}

